{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wordcount-spark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSzcs5rQkLkdB2egNX4xPV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wcj365/word-count/blob/master/wordcount_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H04ZWML-EmR2",
        "colab_type": "text"
      },
      "source": [
        "# Simple Word Count Program\n",
        "## Use Apache Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSJg1KgzVtWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "15618669-2a51-4221-af80-748c3758b8c8"
      },
      "source": [
        "# Install spark-related dependencies\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "\n",
        "!pip install pyspark"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 71kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 50.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=c174dcdb317444370a27c87f52e6ee5c820dfe9640ce2b7e8a505aad2bcf30aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hplNm2ZkH5uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "\n",
        "FILE = \"hamlet.txt\"     \n",
        "APP_NAME = \"Word Count\"        # Spark application name\n",
        "SPARK_URL = \"local[*]\"         # Spark master URL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZBHB6lvWC3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up Spark required environment variables\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwhojRBaWfSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa175cbe-98c1-4de2-8931-07e755cfffbd"
      },
      "source": [
        "# Test if Spark works properly\n",
        "\n",
        "conf = SparkConf().setAppName(APP_NAME).setMaster(SPARK_URL)\n",
        "\n",
        "sc = SparkContext.getOrCreate(conf)\n",
        "\n",
        "a = sc.parallelize(range(4))    # Initial the RDD\n",
        "\n",
        "a.collect()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tXL75rz6pnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a sameple data file\n",
        "\n",
        "with open(FILE, \"w\") as file:   # \"w\" = write\n",
        "    file.write(\"To be or\\n\")            # \"\\n\" = new line\n",
        "    file.write(\"Not to be\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64jH1cthbYU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c939a418-b70a-4c8a-d595-97cc0d8ed618"
      },
      "source": [
        "# read the file into Spark\n",
        "\n",
        "words = sc.textFile(\"hamlet.txt\")\n",
        "\n",
        "words.count()        # how many lines?  "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vj6AIkqcbW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74e6bed8-7df8-47b7-8ae7-e7191b797f2b"
      },
      "source": [
        "# Take the first 10 lines   \n",
        "       \n",
        "words.take(10) "
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['To be or', 'Not to be']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDeUprsxcja3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a343d4fe-c5ed-4054-b489-6ac4281047ff"
      },
      "source": [
        "# Collect all lines \n",
        "# Don't do this if the file is large because this tries \n",
        "# to get data from # all note to the driver application\n",
        "\n",
        "words.collect()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['To be or', 'Not to be']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5E6v1FUc-Mz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b23f07af-0694-44b8-b07b-ad22bb3d691a"
      },
      "source": [
        "# Split the lines into words\n",
        "\n",
        "words2 = words.flatMap(lambda line : line.split(\" \"))\n",
        "words2.take(20)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['To', 'be', 'or', 'Not', 'to', 'be']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-I3TcO2ddky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e9d16b2-c959-4d75-f638-06a1a0cf5e43"
      },
      "source": [
        "# Cover each entry to a tuple of (<lower-case word>, 1)\n",
        "# So that we can count later\n",
        "\n",
        "words3 = words2.map(lambda word : (word.lower(), 1))\n",
        "words3.take(10)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 1), ('be', 1), ('or', 1), ('not', 1), ('to', 1), ('be', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MejmJfpueSXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f02d304d-df9e-449d-d7d9-b714884ee3d3"
      },
      "source": [
        "# Perform the counting\n",
        "\n",
        "words4 = words3.reduceByKey(lambda word, count : word +count)\n",
        "\n",
        "words4.take(10)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 2), ('be', 2), ('or', 1), ('not', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn2CytSSawSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the RDD to folder \"output\"\n",
        "\n",
        "if os.path.exists(\"output\"):\n",
        "    shutil.rmtree(\"output\")\n",
        "    \n",
        "words4.saveAsTextFile(\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXKwDmsTH3I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete the file\n",
        "\n",
        "os.remove(FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvsIVHvR6j0J",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}